{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning with keras : Introduction\n",
    "\n",
    "Keras is a high level framework for doing deep learning and is based on tensorflow. It is very to use and allows to build standard neural networks. It allows has utilities to load standard dataset like mnist. \n",
    "\n",
    "The (not so good) documentation can be found at https://keras.io/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how you can download and Load the MNIST dataset with keras. What is the type of the variables returned by keras? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, (60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train), x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(x_train[88], cmap=\"gray\")\n",
    "y_train[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(\n",
    "    -1,# -1 means compute automatically the dimension (should be 60000)\n",
    "    28, # nb rows\n",
    "    28, #nb cols\n",
    "    1 # one channel for gray images\n",
    ") / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display one image or two of the MNIST dataset once it is loaded with opencv, matplotlib or skimage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "#Convolution = do the feature engineering\n",
    "#Flatten transform array into vector\n",
    "# Dense layers are used for classification\n",
    "from keras import Sequential\n",
    "#Sequential is used to assemble layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build our first Neural network ! For that we will use what is called the sequential API of Keras. Import the Sequential module, and the Dense, Convolutional and Flatten Layers as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the network we will try to instanciate a convolutional layer. What is the kernel size ? What is the activation function ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convLayer = Conv2D(\n",
    "    128,#number of neurones\n",
    "    kernel_size=(3, 3) # size of the convolution (the window)\n",
    ") #kernel_size = windows size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with the Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseLayer = Dense(\n",
    "    65,#number of neurones\n",
    "    activation=\"relu\" #activation function relu(x) = max(0, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the model for real. Instantiate the Sequential class and put the object in the variable **model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(\n",
    "    64, \n",
    "    kernel_size=(3,3), \n",
    "    input_shape=(28,28, 1) #The first layer must have the input dimension\n",
    "    #the next ones are computed automatically\n",
    "))\n",
    "model.add(Conv2D(128, kernel_size=(4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"SGD\", \n",
    "              loss=\"sparse_categorical_crossentropy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 23, 23, 128)       131200    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 400)               27085200  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 27,221,050\n",
      "Trainable params: 27,221,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 9664/60000 [===>..........................] - ETA: 9:34 - loss: 0.5570"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0474d1ddea2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m           \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "          x_train,\n",
    "          y_train,\n",
    "          epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add One Convolutional layer, A Flatten layer  and two Dense layer in the model with the method `add`. Put at the last layer the activation function softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the compile method on your model. What arguments does it require ? What is an optimiser ? What is a loss ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the train data. You can specify the validation argument. Is the performance good ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more convolutional layer and more Dense layers. What happens ? Does it improve the model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not try to normalise your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
