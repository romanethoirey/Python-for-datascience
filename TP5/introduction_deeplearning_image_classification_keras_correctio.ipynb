{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning with keras : Introduction\n",
    "\n",
    "Keras is a high level framework for doing deep learning and is based on tensorflow. It is very to use and allows to build standard neural networks. It allows has utilities to load standard dataset like mnist. \n",
    "\n",
    "The (not so good) documentation can be found at https://keras.io/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how you can download and Load the MNIST dataset with keras. What is the type of the variables returned by keras? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, (60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train), x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(x_train[88], cmap=\"gray\")\n",
    "y_train[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(\n",
    "    -1,# -1 means compute automatically the dimension (should be 60000)\n",
    "    28, # nb rows\n",
    "    28, #nb cols\n",
    "    1 # one channel for gray images\n",
    ") / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display one image or two of the MNIST dataset once it is loaded with opencv, matplotlib or skimage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "#Convolution = do the feature engineering\n",
    "#Flatten transform array into vector\n",
    "# Dense layers are used for classification\n",
    "from keras import Sequential\n",
    "#Sequential is used to assemble layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build our first Neural network ! For that we will use what is called the sequential API of Keras. Import the Sequential module, and the Dense, Convolutional and Flatten Layers as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the network we will try to instanciate a convolutional layer. What is the kernel size ? What is the activation function ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convLayer = Conv2D(\n",
    "    128,#number of neurones\n",
    "    kernel_size=(3, 3) # size of the convolution (the window)\n",
    ") #kernel_size = windows size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with the Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseLayer = Dense(\n",
    "    65,#number of neurones\n",
    "    activation=\"relu\" #activation function relu(x) = max(0, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the model for real. Instantiate the Sequential class and put the object in the variable **model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/romane/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(\n",
    "    64, \n",
    "    kernel_size=(3,3), \n",
    "    input_shape=(28,28, 1) #The first layer must have the input dimension\n",
    "    #the next ones are computed automatically\n",
    "))\n",
    "model.add(Conv2D(128, kernel_size=(4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"SGD\", \n",
    "              loss=\"sparse_categorical_crossentropy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       131200    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               27085200  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 27,221,050\n",
      "Trainable params: 27,221,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18880/60000 [========>.....................] - ETA: 9:41 - loss: 0.4739"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "          x_train,\n",
    "          y_train,\n",
    "          epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add One Convolutional layer, A Flatten layer  and two Dense layer in the model with the method `add`. Put at the last layer the activation function softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the compile method on your model. What arguments does it require ? What is an optimiser ? What is a loss ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the train data. You can specify the validation argument. Is the performance good ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more convolutional layer and more Dense layers. What happens ? Does it improve the model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not try to normalise your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
